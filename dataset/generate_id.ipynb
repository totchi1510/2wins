from pathlib import Path
import json, hashlib
import pandas as pd
from torchvision import datasets
from torch.utils.data import Subset

# ==== ユーザー環境に合わせて ====
DATA_ROOT = Path("/content/data_splits")  # 例: class フォルダが並ぶルート
OUT_DIR   = Path("./splits"); OUT_DIR.mkdir(parents=True, exist_ok=True)

# 例:
# - すでに ImageFolder(DATA_ROOT/"train") と ImageFolder(DATA_ROOT/"val") を使っている
# - あるいは ImageFolder(DATA_ROOT) の Subset(train_idx), Subset(val_idx) を使っている
# どちらでも動くように関数で吸い出します。

def sha1_of_file(p: Path, chunk=1024*1024):
    h = hashlib.sha1()
    with open(p, "rb") as f:
        while True:
            b = f.read(chunk)
            if not b: break
            h.update(b)
    return h.hexdigest()

def dump_split_from_imagefolder(folder: Path):
    ds = datasets.ImageFolder(folder)
    class_to_idx = ds.class_to_idx
    rows = []
    for fp, y in ds.samples:  # (abs_path, class_idx)
        fp = Path(fp)
        rel = fp.relative_to(folder).as_posix()  # train/val 下の相対
        cls = ds.classes[y]
        rows.append({
            "rel_path": rel,
            "label": cls,
            "class_idx": y,
            "sha1": sha1_of_file(fp)
        })
    return pd.DataFrame(rows), class_to_idx

def dump_split_from_dataset(ds, root: Path):
    # ds: ImageFolder もしくは Subset(ImageFolder)
    base = ds.dataset if isinstance(ds, Subset) else ds
    assert isinstance(base, datasets.ImageFolder), "ImageFolder ベースを想定"

    class_to_idx = base.class_to_idx
    idxs = ds.indices if isinstance(ds, Subset) else range(len(base.samples))

    rows = []
    for i in idxs:
        fp, y = base.samples[i]
        fp = Path(fp)
        rel = fp.relative_to(root).as_posix()
        cls = base.classes[y]
        rows.append({
            "rel_path": rel,
            "label": cls,
            "class_idx": y,
            "sha1": sha1_of_file(fp)
        })
    return pd.DataFrame(rows), class_to_idx

# ==== 使い方その1: すでに train/val ディレクトリがある場合 ====
if (DATA_ROOT/"train").exists() and (DATA_ROOT/"val").exists():
    df_train, c2i = dump_split_from_imagefolder(DATA_ROOT/"train")
    df_val,   _   = dump_split_from_imagefolder(DATA_ROOT/"val")
    # class_to_idx は train 側のものを採用（同じはずだが念のため固定）
    (OUT_DIR/"train_list.csv").write_text(df_train.to_csv(index=False), encoding="utf-8")
    (OUT_DIR/"val_list.csv").write_text(df_val.to_csv(index=False), encoding="utf-8")
    (OUT_DIR/"class_to_idx.json").write_text(json.dumps(c2i, ensure_ascii=False, indent=2))
    print("Saved splits from train/val folders ->", OUT_DIR)

# ==== 使い方その2: 1ルート＋Subsetで分けている場合 ====
# 下の例は “学習時に使っていた train_ds / val_ds オブジェクト” がまだ手元にある場合
# ない場合はスキップしてください。
try:
    # 例: train_ds, val_ds が現在のノートブックにあるとして…
    df_train2, c2i2 = dump_split_from_dataset(train_ds, DATA_ROOT)
    df_val2,   _    = dump_split_from_dataset(val_ds,   DATA_ROOT)

    (OUT_DIR/"train_list.csv").write_text(df_train2.to_csv(index=False), encoding="utf-8")
    (OUT_DIR/"val_list.csv").write_text(df_val2.to_csv(index=False), encoding="utf-8")
    (OUT_DIR/"class_to_idx.json").write_text(json.dumps(c2i2, ensure_ascii=False, indent=2))
    print("Saved splits from existing Dataset objects ->", OUT_DIR)
except NameError:
    pass  # train_ds / val_ds が無ければここはスキップ
